# Aranea Web Corpora

<http://aranea.juls.savba.sk/>

Задание для семинара: <https://docs.google.com/document/d/1DEzUg6ugAJB6lVk-CplARI6w3qBBqK-UPWRdRPPiURM/edit>

Aranea Web Corpora - семейство сравнимых веб-корпусов. Есть для большого количества языков:
* Anglicum  - английский (Anglicum Africanum - африканский английский, Anglicum Asiaticum - азиатский английский)
* Bohemicum - чешский
* Bulgaricum - болгарский
* Finnicum -финский
* Francogallicum -французский
* Germanicum -немецкий
* Hispanicum -испанский
* Hungaricum -венгерский 
* Italicum - итальянский
* Nederlandicum - голландский
* Polonicum - польский
* Russicum - русский
* Sinicum - китайский
* Slovacum - словацкий

**Что значит сравнимых?**

Очевидно, что мы не можем сравнивать данные художественных текстов на английском языке 19 века и устную речь на русском языке 21 века. Однако иногда нужно проводить кросс-лингвистические исследования, и тогда нужны корпуса на разных языках не с одинаковыми (как в параллельном корпусе), а с похожими текстами. С помощью корпусов семейства Aranea можно проводить такие исследования. Все эти корпуса содержат тексты примерно с примерно одинаковым распределением текстов по времени (в основном современные тексты), стилям и тематикам (например, мы можем предположить, что тематики новостей примерно одинаковы в разных странах).

**Что значит веб?**

Эти корпуса были созданы посредством обкачивания Интернет-ресурсов на соответствующих языках. Что хорошо - много данных! Что плохо - нужно уделить особое внимание предобработке текстов. Основные проблемы: дублирующиеся тексты и опечатки, включая те, что возникли во время скачивания текста с веба.

## Типы поиска

* леммы - искать все словоформы, имеющие данную лемму
* словоформы - искать конкретную словоформу
* фразы - искать несколько словоформ в цепочке
* CQL (Corpus Query Language) - мудреный язык, позволяющий делать мудреные запросы

## Как делать запросы на CQL

[Вот тут отлично написано](https://www.sketchengine.co.uk/documentation/corpus-querying/). Дублирую ключевые моменты:
* Каждое слово задаётся квадратными скобочками `[]`. 
* Внутри этих скобочек мы пишет атрибут, по которому хотим искать слово, и его значение. Например, `[word="mothers"]` ищет все случаи употребления словоформы `mothers`, а `[lemma="mother"]` ищет все слова с леммой `mother` (предыдущий запрос тоже сюда попадёт).
* Атрибуты есть такие: lemma, word, lempos, tag (и несколько других)
* Тэги перечислены тут -- <http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/Penn-Treebank-Tagset.pdf>
* Атрибуты можно сочетать:
    * `[word="test" & tag!="V.*"]`
    * `[word="test" & !tag="V.*"]`
    * `[!(word="test" & tag="V.*")]`
    * `[word="test.*" & (tag="VVN" | tag="VP")]`
* Можно искать слова, идущие не подряд: `"confuse.*" []{0,10} [tag="IN" | tag="PP"]` - от 0 до 10 слов может стоять между словом, начинающимся с `confuse` и предлогом или личным местоимением.
* Ну и можно ещё много чего, об этом подробнее по ссылке.

## Что можно делать?

* сортировать - по правому контексту, по левому контексту, по найденной форме (сначала Shine, потом shine, потом shines)
* менять формат выдачи - KWIC (Key Word In a Context = конкорданс), по предложениям
* искать коллокации - про это ниже
* смотреть данные о частотности и распределении грамматических форм в корпусе - какой части речи больше, какой формы больше
* сохранять данные поиска (что круто)

## Что такое коллокации?

Как вам нравятся такие предложения:

_I hope to succeed the goal._

_The tailor operated on my sleeves._

_I highly disagree with the opinion._

**Что-то не то, правда?**

Ещё парочка примеров:
<table>
<tr><th>Можно сказать</th><th>Нельзя сказать</th></tr>
<tr>
<td>
<ul>
<li>do homework</li>
<li>long lengths</li>
<li>cause problems</li>
<li>provide care</li>
</ul>
</td>
<td>
<ul>
<li>make homework</li>
<li>lengthy legs</li>
<li>cause solutions</li>
<li>provide harm</li>
</ul>
</td>
</tr>
</table>

Коллокацией называется словосочетание, имеющее признаки синтаксически и семантически целостной единицы, в которой выбор одного слова диктует выбор другого. Коллокации - не идиомы!

## Откуда берутся коллокации?

Не совсем понятно, почему именно эти два (или больше) слова объединяются в целостную единицу. Это может быть продиктовано даже простой традицией. Однако совершенно ясно, как можно искать коллокации! Нужно искать два слова, которые часто встречаются вместе. Но так ли всё просто?

Предположим, что слова в языке стоят в случайном порядке и их сочетаемость имеет случайный характер. Давайте ссыплем все слова из корпуса в большой мешок, перемешаем, распределим случайным образом по мешочкам-текстам, а далее выложим по канавкам-предложениям. Оценим вероятность того, что два слова окажутся рядом. Если гипотеза верна, то вероятность появления биграмма on in окажется весьма велика, да и сочетание also suggest будет вполне предсказуема, так как каждое из слов встречается с большой частотой. Вместе с тем, вероятность случайного появления рядом слов heartily и endorse (да еще именно в таком порядке) чрезвычайно мала - ведь каждое слово довольно редкое. Можно понять, что сочетаемость слов имеет разную "цену", или значимость.

## Разные оценки связи
* T-score
* MI
* log-likelihood
* Dice

**Можно ли по корпусной выдаче понять, в чём между ними разница?**